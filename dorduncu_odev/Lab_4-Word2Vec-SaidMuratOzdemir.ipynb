{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-4: Word2Vec Anlama ve Uygulama\n",
    "\n",
    "Bu not defteri, verilen öğretim/öğrenme metni üzerinde Word2Vec eğitimini, benzer kelime sorgularını ve 2B görselleştirmeyi içerir.\n",
    "\n",
    "Beklenen çıktılar:\n",
    "- \"university\", \"teacher\", \"student\", \"learning\" için en benzer 10 kelime\n",
    "- \"student\" kelimesi için vektörün ilk 10 bileşeni\n",
    "- PCA ile 2-B görselleştirme\n",
    "- Analiz: 3 en yakın komşu anlamlı mı? Korpus boyutu tartışması ve stop-words kaldırmayı deneme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri içe aktar\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seed değeri (tekrarlanabilir sonuçlar için)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (İsteğe bağlı) Gerekli kütüphaneler yoksa yükleyin\n",
    "# !pip -q install gensim nltk scikit-learn matplotlib\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK stopwords (ağ yoksa yerleşik yedek liste)\n",
    "STOPWORDS = None\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "except Exception:\n",
    "    STOPWORDS = {\n",
    "        'the','and','is','are','am','be','been','being','a','an','to','of','in','on','for','with','at','by','from','as',\n",
    "        'that','this','it','its','into','through','during','within','between','over','under','above','below','than','then',\n",
    "        'so','too','very','can','will','just','not','only','but','also','now','such','own','same','no','nor','do','does',\n",
    "        'did','doing','have','has','had','having','because','while','if','until','again','further','once','who','whom',\n",
    "        'which','what','when','where','why','how','all','any','both','each','few','more','most','other','some','your',\n",
    "        'yours','yourself','yourselves','our','ours','ourselves','their','theirs','themselves','i','me','my','mine','we',\n",
    "        'us','he','him','his','she','her','hers','they','them','you'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi yükle\n",
    "CORPUS_PATH = 'dorduncu_odev/teaching_learning_corpus.txt'\n",
    "with open(CORPUS_PATH, 'r') as f:\n",
    "    raw_text = f.read()\n",
    "print('Karakter sayısı:', len(raw_text))\n",
    "print(raw_text[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basit tokenizasyon ve cümlelere bölme\n",
    "def tokenize(s: str):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^a-z\\s]', ' ', s)  # sadece ASCII harfler\n",
    "    toks = [t for t in s.split() if t]\n",
    "    return toks\n",
    "\n",
    "raw_sents = re.split(r'[\\n\\.]+' , raw_text)\n",
    "sentences = [tokenize(s) for s in raw_sents if s.strip()]\n",
    "print('Cümle sayısı:', len(sentences))\n",
    "print('Toplam token:', sum(len(s) for s in sentences))\n",
    "sentences[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec (baseline) eğitimi\n",
    "w2v_base = Word2Vec(\n",
    "    sentences=sentences, vector_size=50, window=5,\n",
    "    min_count=1, workers=1, sg=1, epochs=300, seed=SEED\n",
    ")\n",
    "vocab_size = len(w2v_base.wv)\n",
    "print('Sözlük boyutu (baseline):', vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anahtar kelimeler için en benzer 10 kelime (baseline)\n",
    "keywords = ['university', 'teacher', 'student', 'learning']\n",
    "def print_topk(model, word, k=10):\n",
    "    if word in model.wv:\n",
    "        sims = model.wv.most_similar(word, topn=k)\n",
    "        for t, sc in sims:\n",
    "            print(f'  {t:15s} {sc:.4f}')\n",
    "        return sims\n",
    "    else:\n",
    "        print('  <OOV> (korpus içinde yok)')\n",
    "        return []\n",
    "\n",
    "baseline_neighbors = {}\n",
    "for w in keywords:\n",
    "    print(f'\n",
    "{w}:')\n",
    "    baseline_neighbors[w] = print_topk(w2v_base, w, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'student' vektörünün ilk 10 bileşeni (baseline)\n",
    "if 'student' in w2v_base.wv:\n",
    "    vec = w2v_base.wv['student'][:10]\n",
    "    print('student vektörü (ilk 10):')\n",
    "    print(' ', ' '.join(f'{x:.4f}' for x in vec))\n",
    "else:\n",
    "    print('student kelimesi korpusta yok (OOV).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 en yakın komşu testi (baseline)\n",
    "test_word = 'learning'\n",
    "if test_word in w2v_base.wv:\n",
    "    sims3 = w2v_base.wv.most_similar(test_word, topn=3)\n",
    "    print(f'Test kelime: {test_word}')\n",
    "    for t, sc in sims3:\n",
    "        print(f'  {t:15s} {sc:.4f}')\n",
    "else:\n",
    "    print('Test kelimesi sözlükte yok (OOV).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yorum: Yukarıdaki 3-NN sonucu, korpus bağlamında 'learning' ile ilişkili \n",
    "eylemler/deneyimler (ör. experiences, models, activities) gibi anlamlı \n",
    "komşular üretir; bu nedenle semantik olarak tutarlıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA ile 2B görselleştirme (baseline)\n",
    "def plot_pca(model, seed_words, topn=5, title='PCA - Baseline'):\n",
    "    selected = set()\n",
    "    for w in seed_words:\n",
    "        if w in model.wv:\n",
    "            selected.add(w)\n",
    "            for t, _ in model.wv.most_similar(w, topn=topn):\n",
    "                selected.add(t)\n",
    "    if not selected:\n",
    "        print('Seçilen kelimeler sözlükte bulunamadı.')\n",
    "        return\n",
    "    labels = list(selected)\n",
    "    X = np.array([model.wv[w] for w in labels])\n",
    "    pca = PCA(n_components=2, random_state=SEED)\n",
    "    XY = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(XY[:,0], XY[:,1], s=30, alpha=0.8)\n",
    "    for (x,y), lab in zip(XY, labels):\n",
    "        plt.text(x+0.01, y+0.01, lab, fontsize=9)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()\n",
    "\n",
    "plot_pca(w2v_base, keywords, topn=5, title='PCA - Baseline (anahtar kelimeler ve komşular)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop-words çıkararak yeniden eğitim\n",
    "sentences_sw = [[t for t in s if t not in STOPWORDS] for s in sentences]\n",
    "w2v_sw = Word2Vec(\n",
    "    sentences=sentences_sw, vector_size=50, window=5,\n",
    "    min_count=1, workers=1, sg=1, epochs=300, seed=SEED\n",
    ")\n",
    "print('Sözlük boyutu (stop-words sonrası):', len(w2v_sw.wv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anahtar kelimeler için en benzer 10 kelime (stop-words sonrası)\n",
    "sw_neighbors = {}\n",
    "for w in keywords:\n",
    "    print(f'\n",
    "{w}:')\n",
    "    sw_neighbors[w] = print_topk(w2v_sw, w, k=10)\n",
    "\n",
    "plot_pca(w2v_sw, keywords, topn=5, title='PCA - Stop-words çıkarılmış model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiz ve Çıktılar\n",
    "\n",
    "Aşağıdaki sonuçlar bu korpus ve hiperparametreler ile elde edilmiştir (özet):\n",
    "\n",
    "- Top-10 (Baseline)\n",
    "  - university: focuses, delivery, on, environment, promoting, within, content, only, not, skills\n",
    "  - teacher: <OOV> (korpusta yok)\n",
    "  - student: methods, strategies, objectives, alignment, overall, successful, require, assessment, engagement, teaching\n",
    "  - learning: experiences, models, activities, personalized, blended, flexible, core, combine, with, classroom\n",
    "\n",
    "- Top-10 (Stop-words çıkarılmış)\n",
    "  - university: focuses, self, regulated, delivery, communication, research, promoting, creativity, skills, ability\n",
    "  - teacher: <OOV> (korpusta yok)\n",
    "  - student: alignment, objectives, strategies, require, methods, successful, overall, engagement, assessment, teaching\n",
    "  - learning: environment, core, blended, within, experiences, models, effective, personalized, classroom, flexible\n",
    "\n",
    "- student vektörü (ilk 10, baseline): 0.1830 -0.2750 -0.0293 -0.0409 -0.0963 -0.0573 0.2792 0.4634 -0.1617 0.4517\n",
    "\n",
    "- 3 en yakın komşu testi (baseline, test: learning): experiences, models, activities → anlamlı (öğrenme bağlamıyla tutarlı).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korpus Boyutu Üzerine\n",
    "- Bu çalışma çok küçük ve tek konulu bir metin üzerinde yapıldığı için kelime vektörleri sınırlı genelleme yapar.\n",
    "- Sık geçmeyen veya hiç geçmeyen kelimeler (ör. 'teacher') OOV kalır; bu da sonuçları etkiler.\n",
    "- Daha büyük ve çeşitli bir korpus (ör. eğitimle ilgili makaleler, haberler) benzerlikleri daha güvenilir hale getirir.\n",
    "- Küçük korpusta yüksek epoch ile bile model, eşdizim bazlı yerel ilişkileri öğrenir; semantik kapsam dardır.\n",
    "- İmkan varsa daha büyük bir korpusla yeniden eğitim denenmelidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop-words Kaldırmanın Etkisi\n",
    "- Fonksiyon kelimeleri temizlemek, içerik kelimeleri arasındaki benzerlik sinyalini güçlendirebilir.\n",
    "- Bu korpusta 'learning' komşuları stop-words kaldırıldıktan sonra daha kavramsal kelimelere (environment, core, effective) kaymıştır.\n",
    "- Ancak çok küçük korpuslarda aşırı temizlik bazı bağlam sinyallerini de azaltabilir; denge önemlidir.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
